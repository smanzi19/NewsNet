{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk import WhitespaceTokenizer\n",
    "from nltk.corpus import stopwords, words, wordnet\n",
    "from nltk.lm import Vocabulary\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import concurrent.futures\n",
    "from torch.optim import Adam\n",
    "from data_loading import process_text_df, NewsText, tensorize_sentences, collate_fn\n",
    "from tqdm.notebook import tqdm\n",
    "from models import NewsNet\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import tensor\n",
    "import matplotlib.pyplot as plt\n",
    "stopwords = stopwords.words()\n",
    "words = words.words() \n",
    "wordnet = wordnet.words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake, true = pd.read_csv('Fake.csv'), pd.read_csv('True.csv')\n",
    "fake['label'] = 'fake'\n",
    "true['label'] = 'true'\n",
    "news = pd.concat((fake, true))\n",
    "news = news.sample(frac=1)\n",
    "news.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = process_text_df(news, ['title', 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.37 s, sys: 1.47 s, total: 4.84 s\n",
      "Wall time: 4min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "p1.process_text_col()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[meryl, streep, probabl, forgot, time, obama, ...</td>\n",
       "      <td>[streep, shame, attempt, paint, trump, heartle...</td>\n",
       "      <td>left-news</td>\n",
       "      <td>Jan 10, 2017</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[risk, deeper, involv, us, weigh, option, afgh...</td>\n",
       "      <td>[washington, reuter, , presid, donald, trump, ...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>April 27, 2017</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[obama, sander, meet, white, hous, wednesday, ...</td>\n",
       "      <td>[washington, reuter, , presid, barack, obama, ...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>January 27, 2016</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[talk, seek, secur, islam, state, withdraw, ra...</td>\n",
       "      <td>[issa, syria, reuter, , remain, islam, state, ...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>October 14, 2017</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[franc, presid, threw, awesom, shade, trump, p...</td>\n",
       "      <td>[french, presid, emmanuel, macron, wast, time,...</td>\n",
       "      <td>News</td>\n",
       "      <td>June 2, 2017</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44893</th>\n",
       "      <td>[japan, air, forc, drill, us, bomber, stealth,...</td>\n",
       "      <td>[tokyo, reuter, , japanes, f15, fighter, tuesd...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>December 12, 2017</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44894</th>\n",
       "      <td>[12, muslim, migrant, gang, rape, 13, yr, old,...</td>\n",
       "      <td>[tell, us, barack, poor, widow, orphan, strate...</td>\n",
       "      <td>politics</td>\n",
       "      <td>Feb 9, 2016</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44895</th>\n",
       "      <td>[msnbc, sourc, say, everyon, network, disturb,...</td>\n",
       "      <td>[polit, pundit, joe, scarborough, donald, trum...</td>\n",
       "      <td>News</td>\n",
       "      <td>February 12, 2016</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44896</th>\n",
       "      <td>[trump, new, york, lawyer, lead, justic, dept,...</td>\n",
       "      <td>[washington, reuter, , presid, donald, trump, ...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>March 17, 2017</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44897</th>\n",
       "      <td>[news, white, unarm, teen, kill, sc, polic, of...</td>\n",
       "      <td>[shartpon, travel, never, mind, smoke, mirrors...</td>\n",
       "      <td>politics</td>\n",
       "      <td>Aug 13, 2015</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>44898 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "0      [meryl, streep, probabl, forgot, time, obama, ...   \n",
       "1      [risk, deeper, involv, us, weigh, option, afgh...   \n",
       "2      [obama, sander, meet, white, hous, wednesday, ...   \n",
       "3      [talk, seek, secur, islam, state, withdraw, ra...   \n",
       "4      [franc, presid, threw, awesom, shade, trump, p...   \n",
       "...                                                  ...   \n",
       "44893  [japan, air, forc, drill, us, bomber, stealth,...   \n",
       "44894  [12, muslim, migrant, gang, rape, 13, yr, old,...   \n",
       "44895  [msnbc, sourc, say, everyon, network, disturb,...   \n",
       "44896  [trump, new, york, lawyer, lead, justic, dept,...   \n",
       "44897  [news, white, unarm, teen, kill, sc, polic, of...   \n",
       "\n",
       "                                                    text       subject  \\\n",
       "0      [streep, shame, attempt, paint, trump, heartle...     left-news   \n",
       "1      [washington, reuter, , presid, donald, trump, ...  politicsNews   \n",
       "2      [washington, reuter, , presid, barack, obama, ...  politicsNews   \n",
       "3      [issa, syria, reuter, , remain, islam, state, ...     worldnews   \n",
       "4      [french, presid, emmanuel, macron, wast, time,...          News   \n",
       "...                                                  ...           ...   \n",
       "44893  [tokyo, reuter, , japanes, f15, fighter, tuesd...     worldnews   \n",
       "44894  [tell, us, barack, poor, widow, orphan, strate...      politics   \n",
       "44895  [polit, pundit, joe, scarborough, donald, trum...          News   \n",
       "44896  [washington, reuter, , presid, donald, trump, ...  politicsNews   \n",
       "44897  [shartpon, travel, never, mind, smoke, mirrors...      politics   \n",
       "\n",
       "                     date label  \n",
       "0            Jan 10, 2017  fake  \n",
       "1         April 27, 2017   true  \n",
       "2       January 27, 2016   true  \n",
       "3       October 14, 2017   true  \n",
       "4            June 2, 2017  fake  \n",
       "...                   ...   ...  \n",
       "44893  December 12, 2017   true  \n",
       "44894         Feb 9, 2016  fake  \n",
       "44895   February 12, 2016  fake  \n",
       "44896     March 17, 2017   true  \n",
       "44897        Aug 13, 2015  fake  \n",
       "\n",
       "[44898 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1.tokenize_sentences()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "l, labs = tensorize_sentences(p1.df.text.apply(lambda sent: sent[:50]), p1.df.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f027b73917ef431dabff8e4ca9242fe9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=50.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "net = NewsNet(p1.vocab, hidden_size=4, embedding_dim=8, num_layers=2)\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "optimizer = Adam(net.parameters(), lr=1e-4, weight_decay=5e-6)\n",
    "idx = len(l) // 4\n",
    "\n",
    "l_tr, labs_tr = l[:2 * idx], labs[:2 * idx]\n",
    "l_val, labs_val = l[2 * idx:3 * idx], labs[2 * idx:3 * idx]\n",
    "l_tst, labs_tst = l[-idx:], labs[-idx:]\n",
    "tr_set = NewsText(l_tr, labs_tr)\n",
    "val_set = NewsText(l_val, labs_val)\n",
    "_, val_set = enumerate(DataLoader(val_set, batch_size=len(val_set), collate_fn=collate_fn)).__next__()\n",
    "val_features, val_labels, val_lens = val_set\n",
    "val_labels = val_labels.unsqueeze(-1).float()\n",
    "loader = DataLoader(tr_set, batch_size=8, collate_fn=collate_fn)\n",
    "loss_list = []\n",
    "val_loss_list = []\n",
    "accuracy_list = []\n",
    "epochs = 50\n",
    "pbar = tqdm(total=epochs)\n",
    "for i in range(epochs):\n",
    "    pbar.update()\n",
    "    for sents, labels, lens in loader:\n",
    "        net.train()\n",
    "        labels = labels.float().unsqueeze(-1)\n",
    "        out = net(sents, lens)\n",
    "        loss = loss_fn(out, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        net.eval()\n",
    "    with torch.no_grad():\n",
    "        val_out = net(val_features, val_lens)\n",
    "        val_loss = loss_fn(val_out, val_labels)\n",
    "        val_loss_list.append(val_loss.item())\n",
    "        val_guesses = torch.round(nn.Sigmoid()(val_out))\n",
    "        accuracy = (val_guesses == val_labels).float().mean().item()\n",
    "        \n",
    "        accuracy_list.append(accuracy)\n",
    "    pbar.set_description(desc=f'Completed {i} out of {epochs}')\n",
    "    loss_list.append(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "pd.Series(loss_list).plot(ax=ax, label='Tr')\n",
    "pd.Series(val_loss_list).plot(ax=ax, label='Val')\n",
    "fig.set_size_inches(fig.get_size_inches() * 1.5)\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_set = NewsText(l_tst, labs_tst)\n",
    "_, tst_set = enumerate(DataLoader(tst_set, batch_size=len(tst_set), collate_fn=collate_fn)).__next__()\n",
    "tst_features, tst_labels, test_lens = tst_set\n",
    "tst_labels = tst_labels.unsqueeze(-1).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    tst_out = net(tst_features, test_lens)\n",
    "    tst_loss = loss_fn(tst_out, tst_labels)\n",
    "    tst_guesses = torch.round(nn.Sigmoid()(tst_out))\n",
    "    accuracy_tst = (tst_guesses == tst_labels).float().mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_tst"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "news",
   "language": "python",
   "name": "news"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
