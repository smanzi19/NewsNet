{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk import WhitespaceTokenizer\n",
    "from nltk.corpus import stopwords, words, wordnet\n",
    "from nltk.lm import Vocabulary\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import concurrent.futures\n",
    "from torch.optim import Adam\n",
    "from data_loading import process_text_df, NewsText, tensorize_sentences, collate_fn\n",
    "from tqdm import tqdm as pbar\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import tensor\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "stopwords = stopwords.words()\n",
    "words = words.words() \n",
    "wordnet = wordnet.words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake, true = pd.read_csv('Fake.csv'), pd.read_csv('True.csv')\n",
    "fake['label'] = 'fake'\n",
    "true['label'] = 'true'\n",
    "news = pd.concat((fake, true))\n",
    "news = news.sample(frac=1)\n",
    "news.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = process_text_df(news, ['title', 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "p1.process_text_col()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1.tokenize_sentences()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l, labs = tensorize_sentences(p1.df.title, p1.df.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self, layer_sequence, add_relu=False):\n",
    "        super(LinearBlock, self).__init__()\n",
    "        num_layers = len(layer_sequence) - 1\n",
    "        layers = []\n",
    "        names = []\n",
    "        for i in range(num_layers):\n",
    "            layers.append(nn.Linear(in_features=layer_sequence[i],\n",
    "                                    out_features=layer_sequence[i + 1],\n",
    "                                    bias=False)\n",
    "                         )\n",
    "            names.append(f'fc{i + 1}')\n",
    "                \n",
    "            if add_relu and i != num_layers - 1:\n",
    "                layers.append(nn.ReLU())\n",
    "                names.append(f'relu{i + 1}')\n",
    "        \n",
    "        self.module_dict = OrderedDict(zip(names, layers))\n",
    "        self.block = nn.Sequential(self.module_dict)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.block(x)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewsNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab, hidden_size=10, embedding_dim=16, num_layers=2):\n",
    "        super(NewsNet, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.word_embeddings = nn.Embedding(num_embeddings=len(vocab), embedding_dim=self.embedding_dim)\n",
    "        self.lstm = nn.LSTM(input_size=self.embedding_dim, \n",
    "                            bias=False, \n",
    "                            hidden_size=self.hidden_size, \n",
    "                            batch_first=True,\n",
    "                            num_layers=self.num_layers)\n",
    "        self.linear_block = LinearBlock([self.hidden_size, self.hidden_size // 2, self.hidden_size, 1])\n",
    "        \n",
    "    def forward(self, s):\n",
    "        \n",
    "        out = self.word_embeddings(s)\n",
    "        out, _ = self.lstm(out)\n",
    "        out = out[:, -1, :]\n",
    "        out = self.linear_block(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = NewsNet(p1.vocab, hidden_size=4, embedding_dim=8)\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "optimizer = Adam(net.parameters(), lr=1e-4, weight_decay=1e-6)\n",
    "idx = len(l) // 4\n",
    "\n",
    "l_tr, labs_tr = l[:-2 * idx], labs[: -2 * idx]\n",
    "l_val, labs_val = l[-2 * idx:-idx], labs[-2 * idx:-idx]\n",
    "l_tst, labs_tst = l[-idx:], labs[-idx:]\n",
    "l_tr, l_val, labs_tr, labs_val = l[:idx], l[idx:], labs[:idx], labs[idx:]\n",
    "tr_set = NewsText(l_tr, labs_tr)\n",
    "val_set = NewsText(l_val, labs_val)\n",
    "_, val_set = enumerate(DataLoader(val_set, batch_size=len(val_set), collate_fn=collate_fn)).__next__()\n",
    "val_features, val_labels = val_set\n",
    "val_labels = val_labels.unsqueeze(-1).float()\n",
    "loader = DataLoader(tr_set, batch_size=8, collate_fn=collate_fn)\n",
    "loss_list = []\n",
    "val_loss_list = []\n",
    "accuracy_list = []\n",
    "epochs = 80\n",
    "for i in range(epochs):\n",
    "    print(f'Epoch {i + 1}')\n",
    "    for sents, labels in pbar(loader):\n",
    "        net.train()\n",
    "        labels = labels.float().unsqueeze(-1)\n",
    "        out = net(sents)\n",
    "        loss = loss_fn(out, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        net.eval()\n",
    "    with torch.no_grad():\n",
    "        val_out = net(val_features)\n",
    "        val_loss = loss_fn(val_out, val_labels)\n",
    "        val_loss_list.append(val_loss.item())\n",
    "        val_guesses = torch.round(nn.Sigmoid()(val_out))\n",
    "        accuracy = (val_guesses == val_labels).float().mean().item()\n",
    "        \n",
    "        accuracy_list.append(accuracy)\n",
    "        \n",
    "    loss_list.append(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "pd.Series(loss_list).plot(ax=ax, label='Tr')\n",
    "pd.Series(val_loss_list).plot(ax=ax, label='Val')\n",
    "fig.set_size_inches(fig.get_size_inches() * 1.5)\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(accuracy_list).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_set = NewsText(l_tst, labs_tst)\n",
    "_, tst_set = enumerate(DataLoader(tst_set, batch_size=len(tst_set), collate_fn=collate_fn)).__next__()\n",
    "tst_features, tst_labels = tst_set\n",
    "tst_labels = tst_labels.unsqueeze(-1).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    tst_out = net(tst_features)\n",
    "    tst_loss = loss_fn(tst_out, tst_labels)\n",
    "#     tst_loss_list.append(tst_loss.item())\n",
    "    tst_guesses = torch.round(nn.Sigmoid()(tst_out))\n",
    "    accuracy_tst = (tst_guesses == tst_labels).float().mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_tst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "news",
   "language": "python",
   "name": "news"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
